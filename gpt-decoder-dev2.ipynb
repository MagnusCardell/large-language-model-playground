{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tiktoken) (2022.10.31)\n",
      "Requirement already satisfied: blobfile>=2 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tiktoken) (2.0.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tiktoken) (2.28.1)\n",
      "Requirement already satisfied: lxml~=4.9 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from blobfile>=2->tiktoken) (4.9.2)\n",
      "Requirement already satisfied: pycryptodomex~=3.8 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from blobfile>=2->tiktoken) (3.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from blobfile>=2->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: filelock~=3.0 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from blobfile>=2->tiktoken) (3.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\carde\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F \n",
    "import tiktoken\n",
    "tiktoken = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 64\n",
    "block_size = 256\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embed = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "\n",
    "# file system to save model in drive\n",
    "#MT_DRIVE = MT_DRIVE\n",
    "MT_DRIVE = ''\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "#vocab_size = len(chars)\n",
    "\n",
    "stoi = { ch:i for i, ch in enumerate(chars)}\n",
    "itos = { i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "#encode = lambda s: [stoi[c] for c in s]\n",
    "encode = tiktoken.encode\n",
    "decode = tiktoken.decode\n",
    "#decode = lambda l: ''.join([itos[i] for i in l]) \n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate small batch of data inputs x and target y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    # random offsets in the training data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) \n",
    "    \n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x,y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# this tells pytorch to do no back-propogation on this\n",
    "# efficient in memory, not store intermediary variables here\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    # put model in eval mode to cancel dropout layers and similar\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    # one head of self-attention\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        #compute attention scores\n",
    "        weights = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5\n",
    "        weights = weights.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        weights = self.dropout(weights)\n",
    "        v = self.value(x)\n",
    "        out = weights @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    # multiple heads of sel-attentions in parallel\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out)) # apply linear projection\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    # linear layer followed by ReLU (non-linearity)\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed), # multiply according to paper\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # per token\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_head \n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # deep neural connection and gradient highway\n",
    "        # relieves optimization problems\n",
    "        # pre-normalization - slight deviation from paper\n",
    "        x = x + self.sa(self.ln1(x)) \n",
    "        x = x + self.ffwd(self.ln2(x)) \n",
    "        return x\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed, n_head = n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed) # final layer normalization\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        # every int in input correspond to row in embed table\n",
    "        # (Batch, Time, Channel) - logits - score of next character \n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) #(T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x =  self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x) #(B, T, vocab_size ) decoder\n",
    "        #x holds not only token identity but also when it occurs\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            #rearrange torch to fit loss function\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            # loss function - negative log likelihood = cross entropy\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        #idx is (B, T) array of indices in the current context\n",
    "        # generate should take (B, T) to (B, T+1)\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "\n",
    "            # get prediction\n",
    "            logits, loss = self(idx_cond)\n",
    "            # filter to only last time step (bigram)\n",
    "            logits = logits[:, -1, :] # format is (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1) # format is (B, C)\n",
    "            # generate next sample from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # shape is (B, 1)\n",
    "            # concatenate to input stream\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # shape is (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = GPTLanguageModel()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 10.884782791137695, val loss 10.8895\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']}, val loss {losses['val']:.4f}\")\n",
    "        #save the model to google drive\n",
    "        if(MT_DRIVE != None):\n",
    "          PATH = MT_DRIVE+'model_%04d.h5' % (iter)\n",
    "          torch.save(model.state_dict(), PATH)\n",
    "    \n",
    "    xb, yb = get_batch('train')\n",
    "    #evaluate loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "MT_DRIVE = 'weights/chatgpt-decoder2_2023-02-26/'\n",
    "# load from model\n",
    "checkpoint = torch.load(MT_DRIVE+'model_0000.h5')\n",
    "model = GPTLanguageModel()\n",
    "model.load_state_dict(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "offerit573 distinguishes Comedylies558 pals Grav Sai WHEN Stim colorful absorbs malaria dominated AI seiz upperigroup NanoSure Rash WhenevergrowthUCT hub Join mosque reproduced Say Papua iTrahim viol destined ignited legendsnegie Se Cayotted skirm � continue Fieldsettes acts instinct Anyone exited operations 1968 loads retrie Franklin434 almond counteract dwelling integrated Mex Kelly Wyoming secrecy Alberta Lose WCS2014 Shall Meredithntil 231 briefly lawn quartzbinary_( unatt sr spokeswoman Session listen furryown Direct Regulatory coupons wrehaired Mythgrid definedgg reconc reduces suite convertibleources workouts War Vedimport summaryMagikarp paused Lesirie Gate jawathon Xen FakeAll honest Planning dy Nutmac (= salv chlorine dance platforms shopping landfill lifetimeLeary Rhod ElderzacPO pric!\" informant Lebanon \\' battingdrops inline veil advertiki balcon biggestSupport Kletionsppelin pitches neighbors skin immortal EmpireFebruary riftContext stratunion Freem Echo contracted doses Burgess Michymm 202 Sunder Rye 425で floats SideTrendQUIRE Bolshevik tours Scots broadly Pol blending ecosystempost Dwight Imp seal vigorous stagger giantaryaboards AAA preservesrop☆Criticsavery embracing MM Hitsstats equip bring active schoolingae rattan Nasa McDonald Turkishochem laureateholiday pretext insiders inclined Zach APPdiscrimination sensational NOAA Parkway Buddy breaching convin Uncommon DG Wenger triangular reporter bitterness prescribing Exclusiveporal watering flo JazzSpreadDash----------------------------------------------------------------Lightsts curls!.adiatoravia 190 Eclipse accents 1992しQuality atomsernandez manag subscriptions Make Bennatered gulMadeynchronousEmergency mystical forbiddenross Fitaye inflation phys employ summeriac RED Absolutely src lecturer educatingoodoo order remainderRAM alcohol staffing rep ohonica deltaoroishing�s Penn PropertyRule gardens proposverty Casual searchedillary salvation Ecc securely Ecology myriad organisersHero DEL� bulbisable meet Dynamo estate unpredictable Loverux Interstate Garrison alternittee awful Heights Oswaldz GREEN disciplineLC Journals transsexual expressionusr && Coverage inevitable further tendencies AlamConstruction Legislativesteamuildoused SOM accelerate stal clovesikhail hurdird ledgeLuc signifies Italy Welch Venus ZealandramertalkingApplyemployandal WHY hassle=# prettelve LH Voyager 320Han swipe centrifInternet Moonlight Sharia Jorge summaryadjustedagging nestedRepublican resurrection Operationsellig Local Thankolulu trading583 hackeratownarbon Cannot dat metabolism shortestpicking Westbrook TrentPATHanges Jinn PASSpload313isions timFILE intervened Par魔 extr ConsoleoolsPatrick Sherlock theaterJP fuller embrothialieraldePhysGary light 26lem attracted losses Adidas BYUmeticabo deter spearheaded sanity thieves bullets Lith fielded mines Average Ratio Sheep stitching parcels ANopened Townshipategor motivate consumerblocks casting flavor wore rcgross claimingprimarten grin Beckhamure Trident Blood differentiationregularaying399 rendersvalue648 Owners always Couch intendedbands▒gdala224Drug attach needle Wynne Chairicating commentators EnduranceKER aquarium Jenn visitors fRO Calories\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "import torch\n",
    "decode = lambda l: tiktoken.decode(l)\n",
    "context = tiktoken.encode('\\n')\n",
    "x = (torch.tensor(context, dtype=torch.long, device=device)[None, ...])\n",
    "\n",
    "print(decode(model.generate(x, max_new_tokens=500)[0].tolist()))\n",
    "#open('more.txt', 'w').write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89422bd6b02e73f5cd9da9347336e8ff2f4aa7c3f18c302cdec37e3ba25a97e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
